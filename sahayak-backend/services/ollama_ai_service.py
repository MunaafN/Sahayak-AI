import os
import logging
import json
import requests
import time
from typing import Optional

logger = logging.getLogger(__name__)

class OllamaAIService:
    """
    Local AI service using Ollama - Completely free with no limits!
    """
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(OllamaAIService, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
            
        self.ollama_url = "http://localhost:11434"
        self.model_name = "llama3:8b"  # Use memory-efficient model
        self.vision_model = "llava-phi3:latest"  # Vision model for worksheets
        self.ollama_available = self._check_ollama_availability()
        
        if self.ollama_available:
            logger.info("Ollama AI service initialized successfully")
            print("âœ… Ollama AI service connected successfully!")
        else:
            logger.warning("Ollama not available. Please install Ollama and download models.")
            print("âš ï¸ Ollama not available. Install from https://ollama.ai/")
            
        self._initialized = True
    
    def _check_ollama_availability(self):
        """Check if Ollama is running and has models available"""
        try:
            # Check if Ollama is running
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json().get('models', [])
                if models:
                    # Check for memory-efficient models first
                    model_names = [model['name'] for model in models]
                    
                    # First priority: llama3:8b (memory-efficient)
                    if "llama3:8b" in model_names:
                        self.model_name = "llama3:8b"
                        print(f"ðŸ“š Using text AI model: {self.model_name}")
                        
                        # Check for vision model
                        if "llava-phi3:latest" in model_names:
                            print(f"ðŸ‘ï¸ Using vision AI model: {self.vision_model}")
                        else:
                            print("âš ï¸ llava-phi3:latest not found for vision features")
                        
                        return True
                    
                    # Fallback to llama3:latest (also memory-efficient)
                    elif "llama3:latest" in model_names:
                        self.model_name = "llama3:latest"
                        print(f"ðŸ“š Using fallback text model: {self.model_name}")
                        return True
                    
                    # Fallback to any llama3.1 variant
                    elif any("llama3.1" in name for name in model_names):
                        for name in model_names:
                            if "llama3.1" in name:
                                self.model_name = name
                                break
                        print(f"ðŸ“š Using fallback text model: {self.model_name}")
                        print("âš ï¸ This model may require more memory")
                        return True
                    
                    # Fallback to any llama3 variant  
                    elif any("llama3" in name for name in model_names):
                        for name in model_names:
                            if "llama3" in name:
                                self.model_name = name
                                break
                        print(f"ðŸ“š Using fallback model: {self.model_name}")
                        return True
                    
                    # Last resort: any llama model
                    elif any("llama" in name for name in model_names):
                        for name in model_names:
                            if "llama" in name:
                                self.model_name = name
                                break
                        print(f"ðŸ“š Using available model: {self.model_name}")
                        return True
                    
                    else:
                        # Use first available model
                        self.model_name = model_names[0]
                        print(f"ðŸ“š Using available model: {self.model_name}")
                        return True
                else:
                    print("âš ï¸ No models found. Run: ollama pull llama3:8b")
                    return False
            return False
        except Exception as e:
            logger.debug(f"Ollama check failed: {e}")
            return False
    
    async def generate_text(self, prompt: str, **kwargs) -> str:
        """
        Generate educational content using local Ollama AI
        
        Args:
            prompt: Text prompt for generation
            **kwargs: Additional parameters (language, content_type, grade_level)
            
        Returns:
            Generated educational content
        """
        try:
            # Add timestamp to ensure fresh responses
            timestamp = int(time.time())
            
            # Extract parameters from frontend
            language = kwargs.get("language", "en")
            content_type = kwargs.get("content_type", "explanation")
            grade_level = kwargs.get("grade_level", "3")
            subject = kwargs.get("subject", "General")
            length = kwargs.get("length", "medium")  # Extract length parameter
            
            # Map content types to actual tab/module names
            content_type_mapping = {
                "lesson_plan": "Lesson Planner",
                "explanation": "Knowledge Base", 
                "content": "Hyper Local Content Generator",
                "worksheet": "Worksheets",
                "visual": "Visual Aids",
                "assessment": "Assessment",
                "answer": "Knowledge Base",
                "story": "Content Generator",
                "example": "Content Generator",
                "activity": "Content Generator"
            }
            
            # Get the actual module name
            module_name = content_type_mapping.get(content_type, content_type.title())
            
            # Display frontend inputs in terminal
            print("=" * 60)
            print("ðŸ“ NEW REQUEST FROM FRONTEND:")
            print(f"   ðŸ“‹ Topic: {prompt}")
            print(f"   ðŸ“š Subject: {subject}")
            print(f"   ðŸŒ Language: {language.upper()}")
            print(f"   ðŸ“Š Content Type: {module_name}")
            print(f"   ðŸŽ“ Grade Level: {grade_level}")
            print(f"   ðŸ†” Request ID: {timestamp}")
            print("=" * 60)
            
            logger.info(f"Processing: {prompt} | {content_type} | Grade {grade_level} | {language}")
            
            if self.ollama_available:
                try:
                    if self._check_ollama_availability():
                        print(f"ðŸ¤– Generating content with Ollama...")
                        print(f"ðŸ“ Prompt Topic: {prompt[:50]}...")
                        print(f"ðŸŒ Language: {language}")
                        print(f"ðŸŽ¯ Grade Level: {grade_level}")
                        print(f"ðŸ“ Length: {length}")
                        print(f"ðŸ“š Content Type: {content_type}")
                        
                        # Create educational prompt with strict language enforcement
                        enhanced_prompt = self._create_educational_prompt(prompt, language, content_type, grade_level, timestamp, length, subject)
                        
                        print(f"ðŸ” Enhanced Prompt Preview: {enhanced_prompt[:200]}...")
                        print(f"ðŸ“Š Prompt Length: {len(enhanced_prompt)} characters")
                        
                        try:
                            response = requests.post(
                                f"{self.ollama_url}/api/generate",
                                json={
                                    "model": self.model_name,
                                    "prompt": enhanced_prompt,
                                    "stream": False,
                                    "options": {
                                        "temperature": 0.7,
                                        "top_p": 0.9,
                                        "num_predict": 500
                                    }
                                },
                                timeout=60
                            )
                            
                            if response.status_code == 200:
                                result = response.json()
                                content = result.get('response', '').strip()
                                
                                print(f"âœ… Generated content successfully")
                                print(f"ðŸ“ Response length: {len(content)} characters")
                                print(f"ðŸ” Response preview: {content[:100]}...")
                                
                                return content
                            
                            elif response.status_code == 500:
                                # Handle HTTP 500 errors with detailed feedback
                                error_text = response.text.lower()
                                print(f"âŒ HTTP 500 Error from Ollama")
                                print(f"ðŸ” Error text: {error_text[:200]}...")
                                
                                try:
                                    error_json = response.json()
                                    error_msg = error_json.get('error', error_text)
                                    print(f"ðŸ“„ Error details: {error_msg}")
                                    
                                    # Check for memory-related errors
                                    if any(term in error_text for term in ['memory', 'insufficient', 'oom', 'out of memory', 'allocation failed']):
                                        error_msg = "Insufficient memory to run AI model. Try restarting Ollama or closing other applications."
                                        print(f"ðŸ§  Memory Error: {error_text}")
                                        print(f"ðŸ’¡ Try: ollama serve --host 0.0.0.0 --origin \"*\"")
                                    else:
                                        error_msg = f"AI model error: {error_text[:100]}..."
                                        print(f"âŒ Model Error: {error_text}")
                                except:
                                    error_msg = "AI model is not responding properly. Please restart Ollama service."
                                    print(f"âŒ HTTP 500: Model not loaded properly")
                                
                                print(f"ðŸ’¡ Suggestion: Stop Ollama, restart it, and try again")
                                print(f"ðŸ“¤ Sending error response to frontend...")
                                return error_msg
                            else:
                                error_msg = f"AI service error: HTTP {response.status_code}"
                                print(f"âŒ {error_msg}")
                                
                                # Try to get error details
                                try:
                                    error_details = response.json()
                                    print(f"ðŸ” Error details: {error_details}")
                                except:
                                    print(f"ðŸ” Raw response: {response.text[:200]}...")
                                
                                return error_msg
                                
                        except requests.exceptions.Timeout:
                            error_msg = "The AI is taking too long to respond. Please try again."
                            print(f"â±ï¸ {error_msg}")
                            return error_msg
                        except Exception as e:
                            error_msg = f"AI service error: {str(e)}"
                            logger.error(f"Ollama API error: {str(e)}")
                            print(f"âŒ {error_msg}")
                            return error_msg
                    
                    # Fallback to educational content if Ollama check fails
                    else:
                        print("âš ï¸ Ollama check failed, using educational fallback")
                        fallback_response = self._generate_educational_fallback(prompt, **kwargs)
                        print(f"ðŸ“¤ Fallback response: {fallback_response[:100]}...")
                        return fallback_response
                        
                except Exception as e:
                    error_msg = f"AI service error: {str(e)}"
                    logger.error(f"Ollama service error: {str(e)}")
                    print(f"âŒ {error_msg}")
                    return error_msg
            
            # Fallback when ollama_available is False
            else:
                print("âš ï¸ Ollama not available, using educational fallback")
                fallback_response = self._generate_educational_fallback(prompt, **kwargs)
                print(f"ðŸ“¤ Fallback response: {fallback_response[:100]}...")
                return fallback_response
            
        except Exception as e:
            error_msg = "I'm sorry, I couldn't generate content at this moment. Please try again."
            logger.error(f"Error generating content: {str(e)}")
            print(f"âŒ Error: {str(e)}")
            print(f"ðŸ“¤ Sending error response to frontend...")
            return error_msg
    
    def _create_educational_prompt(self, prompt: str, language: str, content_type: str, grade_level: str, timestamp: int, length: str = "medium", subject: str = "General") -> str:
        """Create educational prompt that STRICTLY enforces language, grade level, and word limits"""
        
        # Define word limits clearly
        word_limits = {
            "short": {"min": 100, "max": 150},
            "medium": {"min": 200, "max": 300}, 
            "long": {"min": 400, "max": 500}
        }
        
        word_count = word_limits.get(length, word_limits["medium"])
        
        # Define grade-specific vocabulary and complexity instructions
        grade_instructions = {
            "1": "Use very simple words that a 6-7 year old can understand. Use short sentences (5-8 words). Avoid complex concepts. Use familiar examples from daily life.",
            "2": "Use simple words that a 7-8 year old can understand. Use short to medium sentences (8-12 words). Use basic concepts. Use examples from home and school.",
            "3": "Use age-appropriate words for 8-9 year olds. Use clear, medium-length sentences (10-15 words). Explain concepts step by step. Use relatable examples.",
            "4": "Use vocabulary suitable for 9-10 year olds. Use well-structured sentences (12-18 words). Include slightly more complex concepts with explanations.",
            "5": "Use vocabulary appropriate for 10-11 year olds. Use detailed sentences (15-20 words). Include more advanced concepts with clear explanations and examples."
        }
        
        grade_instruction = grade_instructions.get(grade_level, grade_instructions["3"])
        
        # ULTRA STRICT LANGUAGE ENFORCEMENT - Create language-specific prompts
        if language == "hi":
            enhanced_prompt = f"""
à¤…à¤¤à¥à¤¯à¤‚à¤¤ à¤®à¤¹à¤¤à¥à¤µà¤ªà¥‚à¤°à¥à¤£ à¤¨à¤¿à¤°à¥à¤¦à¥‡à¤¶: à¤†à¤ªà¤•à¥‹ à¤•à¥‡à¤µà¤² à¤”à¤° à¤•à¥‡à¤µà¤² à¤¹à¤¿à¤‚à¤¦à¥€ à¤®à¥‡à¤‚ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥‡à¤¨à¤¾ à¤¹à¥ˆà¥¤ à¤à¤• à¤­à¥€ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤¶à¤¬à¥à¤¦ à¤•à¤¾ à¤ªà¥à¤°à¤¯à¥‹à¤— à¤¨ à¤•à¤°à¥‡à¤‚à¥¤

ABSOLUTELY NO ENGLISH WORDS ALLOWED. HINDI ONLY. à¤¦à¥‡à¤µà¤¨à¤¾à¤—à¤°à¥€ à¤®à¥‡à¤‚ à¤²à¤¿à¤–à¥‡à¤‚à¥¤

à¤µà¤¿à¤·à¤¯: {subject}
à¤•à¤•à¥à¤·à¤¾: {grade_level}
à¤ªà¥à¤°à¤¶à¥à¤¨/à¤Ÿà¥‰à¤ªà¤¿à¤•: {prompt}
à¤ªà¥à¤°à¤•à¤¾à¤°: {content_type}
à¤¶à¤¬à¥à¤¦ à¤¸à¥€à¤®à¤¾: {word_count['min']}-{word_count['max']} à¤¶à¤¬à¥à¤¦

à¤¨à¤¿à¤°à¥à¤¦à¥‡à¤¶:
1. à¤•à¥‡à¤µà¤² à¤¹à¤¿à¤‚à¤¦à¥€ à¤­à¤¾à¤·à¤¾ à¤®à¥‡à¤‚ à¤²à¤¿à¤–à¥‡à¤‚ - à¤•à¥‹à¤ˆ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤¨à¤¹à¥€à¤‚
2. {word_count['min']}-{word_count['max']} à¤¶à¤¬à¥à¤¦à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¹à¥€ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥‡à¤‚
3. à¤•à¤•à¥à¤·à¤¾ {grade_level} à¤•à¥‡ à¤…à¤¨à¥à¤¸à¤¾à¤° à¤¶à¤¬à¥à¤¦à¤¾à¤µà¤²à¥€ à¤•à¤¾ à¤ªà¥à¤°à¤¯à¥‹à¤— à¤•à¤°à¥‡à¤‚
4. {grade_instruction}

à¤®à¤¹à¤¤à¥à¤µà¤ªà¥‚à¤°à¥à¤£: à¤ªà¥‚à¤°à¤¾ à¤‰à¤¤à¥à¤¤à¤° à¤•à¥‡à¤µà¤² à¤¹à¤¿à¤‚à¤¦à¥€ à¤®à¥‡à¤‚ à¤¦à¥‡à¤‚à¥¤ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤•à¤¾ à¤à¤• à¤­à¥€ à¤¶à¤¬à¥à¤¦ à¤¨ à¤²à¤¿à¤–à¥‡à¤‚à¥¤

à¤…à¤¬ '{prompt}' à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚ à¤¹à¤¿à¤‚à¤¦à¥€ à¤®à¥‡à¤‚ {content_type} à¤²à¤¿à¤–à¥‡à¤‚:
"""
        
        elif language == "mr":
            enhanced_prompt = f"""
à¤…à¤¤à¥à¤¯à¤‚à¤¤ à¤®à¤¹à¤¤à¥à¤¤à¥à¤µà¤¾à¤šà¥‡ à¤¸à¥‚à¤šà¤¨à¤¾: à¤¤à¥à¤®à¥à¤¹à¤¾à¤²à¤¾ à¤«à¤•à¥à¤¤ à¤†à¤£à¤¿ à¤«à¤•à¥à¤¤ à¤®à¤°à¤¾à¤ à¥€à¤¤ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥à¤¯à¤¾à¤¯à¤šà¥‡ à¤†à¤¹à¥‡à¥¤ à¤à¤•à¤¹à¥€ à¤‡à¤‚à¤—à¥à¤°à¤œà¥€ à¤¶à¤¬à¥à¤¦ à¤µà¤¾à¤ªà¤°à¥‚ à¤¨à¤•à¤¾à¥¤

ABSOLUTELY NO ENGLISH WORDS ALLOWED. MARATHI ONLY. à¤¦à¥‡à¤µà¤¨à¤¾à¤—à¤°à¥€ à¤®à¥‡à¤‚ à¤²à¤¿à¤–à¥‡à¤‚à¥¤

à¤µà¤¿à¤·à¤¯: {subject}
à¤‡à¤¯à¤¤à¥à¤¤à¤¾: {grade_level}
à¤ªà¥à¤°à¤¶à¥à¤¨/à¤µà¤¿à¤·à¤¯: {prompt}
à¤ªà¥à¤°à¤•à¤¾à¤°: {content_type}
à¤¶à¤¬à¥à¤¦ à¤®à¤°à¥à¤¯à¤¾à¤¦à¤¾: {word_count['min']}-{word_count['max']} à¤¶à¤¬à¥à¤¦

à¤¸à¥‚à¤šà¤¨à¤¾:
1. à¤«à¤•à¥à¤¤ à¤®à¤°à¤¾à¤ à¥€ à¤­à¤¾à¤·à¥‡à¤¤ à¤²à¤¿à¤¹à¤¾ - à¤•à¥‹à¤£à¤¤à¤¾à¤¹à¥€ à¤‡à¤‚à¤—à¥à¤°à¤œà¥€ à¤¨à¤¾à¤¹à¥€
2. {word_count['min']}-{word_count['max']} à¤¶à¤¬à¥à¤¦à¤¾à¤‚à¤¤ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥à¤¯à¤¾
3. à¤‡à¤¯à¤¤à¥à¤¤à¤¾ {grade_level} à¤šà¥à¤¯à¤¾ à¤…à¤¨à¥à¤¸à¤¾à¤° à¤¶à¤¬à¥à¤¦à¤¾à¤µà¤²à¥€ à¤µà¤¾à¤ªà¤°à¤¾
4. {grade_instruction}

à¤®à¤¹à¤¤à¥à¤¤à¥à¤µà¤¾à¤šà¥‡: à¤¸à¤‚à¤ªà¥‚à¤°à¥à¤£ à¤‰à¤¤à¥à¤¤à¤° à¤«à¤•à¥à¤¤ à¤®à¤°à¤¾à¤ à¥€à¤¤ à¤¦à¥à¤¯à¤¾à¥¤ à¤‡à¤‚à¤—à¥à¤°à¤œà¥€à¤šà¤¾ à¤à¤•à¤¹à¥€ à¤¶à¤¬à¥à¤¦ à¤²à¤¿à¤¹à¥‚ à¤¨à¤•à¤¾à¥¤

à¤†à¤¤à¤¾ '{prompt}' à¤¬à¤¦à¥à¤¦à¤² à¤®à¤°à¤¾à¤ à¥€à¤¤ {content_type} à¤²à¤¿à¤¹à¤¾:
"""
        
        elif language == "bn":
            enhanced_prompt = f"""
à¦…à¦¤à§à¦¯à¦¨à§à¦¤ à¦—à§à¦°à§à¦¤à§à¦¬à¦ªà§‚à¦°à§à¦£ à¦¨à¦¿à¦°à§à¦¦à§‡à¦¶à¦¨à¦¾: à¦†à¦ªà¦¨à¦¾à¦•à§‡ à¦•à§‡à¦¬à¦²à¦®à¦¾à¦¤à§à¦° à¦¬à¦¾à¦‚à¦²à¦¾à¦¯à¦¼ à¦‰à¦¤à§à¦¤à¦° à¦¦à¦¿à¦¤à§‡ à¦¹à¦¬à§‡à¥¤ à¦à¦•à¦Ÿà¦¿ à¦‡à¦‚à¦°à§‡à¦œà¦¿ à¦¶à¦¬à§à¦¦à¦“ à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à¦¬à§‡à¦¨ à¦¨à¦¾à¥¤

ABSOLUTELY NO ENGLISH WORDS ALLOWED. BENGALI ONLY. à¦¬à¦¾à¦‚à¦²à¦¾à¦¯à¦¼ à¦²à¦¿à¦–à§à¦¨à¥¤

à¦¬à¦¿à¦·à¦¯à¦¼: {subject}
à¦¶à§à¦°à§‡à¦£à§€: {grade_level}
à¦ªà§à¦°à¦¶à§à¦¨/à¦¬à¦¿à¦·à¦¯à¦¼: {prompt}
à¦§à¦°à¦¨: {content_type}
à¦¶à¦¬à§à¦¦ à¦¸à§€à¦®à¦¾: {word_count['min']}-{word_count['max']} à¦¶à¦¬à§à¦¦

à¦¨à¦¿à¦°à§à¦¦à§‡à¦¶à¦¨à¦¾:
1. à¦•à§‡à¦¬à¦² à¦¬à¦¾à¦‚à¦²à¦¾ à¦­à¦¾à¦·à¦¾à¦¯à¦¼ à¦²à¦¿à¦–à§à¦¨ - à¦•à§‹à¦¨ à¦‡à¦‚à¦°à§‡à¦œà¦¿ à¦¨à¦¯à¦¼
2. {word_count['min']}-{word_count['max']} à¦¶à¦¬à§à¦¦à§‡ à¦‰à¦¤à§à¦¤à¦° à¦¦à¦¿à¦¨
3. à¦¶à§à¦°à§‡à¦£à§€ {grade_level} à¦…à¦¨à§à¦¯à¦¾à¦¯à¦¼à§€ à¦¶à¦¬à§à¦¦à¦­à¦¾à¦£à§à¦¡à¦¾à¦° à¦¬à§à¦¯à¦¬à¦¹à¦¾à¦° à¦•à¦°à§à¦¨
4. {grade_instruction}

à¦—à§à¦°à§à¦¤à§à¦¬à¦ªà§‚à¦°à§à¦£: à¦¸à¦®à§à¦ªà§‚à¦°à§à¦£ à¦‰à¦¤à§à¦¤à¦° à¦•à§‡à¦¬à¦² à¦¬à¦¾à¦‚à¦²à¦¾à¦¯à¦¼ à¦¦à¦¿à¦¨à¥¤ à¦‡à¦‚à¦°à§‡à¦œà¦¿à¦° à¦à¦•à¦Ÿà¦¿ à¦¶à¦¬à§à¦¦à¦“ à¦²à¦¿à¦–à¦¬à§‡à¦¨ à¦¨à¦¾à¥¤

à¦à¦–à¦¨ '{prompt}' à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦¬à¦¾à¦‚à¦²à¦¾à¦¯à¦¼ {content_type} à¦²à¦¿à¦–à§à¦¨:
"""
        
        elif language == "te":
            enhanced_prompt = f"""
à°…à°¤à±à°¯à°‚à°¤ à°®à±à°–à±à°¯à°®à°¾à°¨ à°¸à±‚à°šà°¨à°²à±: à°®à±€à°°à± à°•à±‡à°µà°²à°‚ à°¤à±†à°²à±à°—à±à°²à±‹ à°®à°¾à°¤à±à°°à°®à±‡ à°¸à°®à°¾à°§à°¾à°¨à°‚ à°‡à°µà±à°µà°¾à°²à°¿. à°’à°•à±à°• à°‡à°‚à°—à±à°²à±€à°·à± à°ªà°¦à°‚ à°•à±‚à°¡à°¾ à°µà°¾à°¡à°•à°‚à°¡à°¿.

ABSOLUTELY NO ENGLISH WORDS ALLOWED. TELUGU ONLY. à°¤à±†à°²à±à°—à±à°²à±‹ à°°à°¾à°¯à°‚à°¡à°¿.

à°µà°¿à°·à°¯à°‚: {subject}
à°¤à°°à°—à°¤à°¿: {grade_level}
à°ªà±à°°à°¶à±à°¨/à°µà°¿à°·à°¯à°‚: {prompt}
à°°à°•à°‚: {content_type}
à°ªà°¦à°¾à°² à°ªà°°à°¿à°®à°¿à°¤à°¿: {word_count['min']}-{word_count['max']} à°ªà°¦à°¾à°²à±

à°¸à±‚à°šà°¨à°²à±:
1. à°•à±‡à°µà°²à°‚ à°¤à±†à°²à±à°—à± à°­à°¾à°·à°²à±‹ à°°à°¾à°¯à°‚à°¡à°¿ - à°‡à°‚à°—à±à°²à±€à°·à± à°µà°¦à±à°¦à±
2. {word_count['min']}-{word_count['max']} à°ªà°¦à°¾à°²à°²à±‹ à°¸à°®à°¾à°§à°¾à°¨à°‚ à°‡à°µà±à°µà°‚à°¡à°¿
3. à°¤à°°à°—à°¤à°¿ {grade_level} à°…à°¨à±à°¸à°¾à°°à°‚ à°ªà°¦à°œà°¾à°²à°‚ à°µà°¾à°¡à°‚à°¡à°¿
4. {grade_instruction}

à°®à±à°–à±à°¯à°‚: à°®à±Šà°¤à±à°¤à°‚ à°¸à°®à°¾à°§à°¾à°¨à°‚ à°•à±‡à°µà°²à°‚ à°¤à±†à°²à±à°—à±à°²à±‹ à°‡à°µà±à°µà°‚à°¡à°¿. à°‡à°‚à°—à±à°²à±€à°·à± à°ªà°¦à°‚ à°°à°¾à°¯à°•à°‚à°¡à°¿.

à°‡à°ªà±à°ªà±à°¡à± '{prompt}' à°—à±à°°à°¿à°‚à°šà°¿ à°¤à±†à°²à±à°—à±à°²à±‹ {content_type} à°°à°¾à°¯à°‚à°¡à°¿:
"""
        
        elif language == "ta":
            enhanced_prompt = f"""
à®®à®¿à®• à®®à¯à®•à¯à®•à®¿à®¯à®®à®¾à®© à®…à®±à®¿à®µà¯à®±à¯à®¤à¯à®¤à®²à¯à®•à®³à¯: à®¨à¯€à®™à¯à®•à®³à¯ à®¤à®®à®¿à®´à®¿à®²à¯ à®®à®Ÿà¯à®Ÿà¯à®®à¯‡ à®ªà®¤à®¿à®²à®³à®¿à®•à¯à®• à®µà¯‡à®£à¯à®Ÿà¯à®®à¯. à®’à®°à¯ à®†à®™à¯à®•à®¿à®² à®µà®¾à®°à¯à®¤à¯à®¤à¯ˆà®¯à¯à®®à¯ à®ªà®¯à®©à¯à®ªà®Ÿà¯à®¤à¯à®¤ à®µà¯‡à®£à¯à®Ÿà®¾à®®à¯.

ABSOLUTELY NO ENGLISH WORDS ALLOWED. TAMIL ONLY. à®¤à®®à®¿à®´à®¿à®²à¯ à®Žà®´à¯à®¤à¯à®™à¯à®•à®³à¯.

à®ªà®¾à®Ÿà®®à¯: {subject}
à®µà®•à¯à®ªà¯à®ªà¯: {grade_level}
à®•à¯‡à®³à¯à®µà®¿/à®¤à®²à¯ˆà®ªà¯à®ªà¯: {prompt}
à®µà®•à¯ˆ: {content_type}
à®µà®¾à®°à¯à®¤à¯à®¤à¯ˆ à®µà®°à®®à¯à®ªà¯: {word_count['min']}-{word_count['max']} à®µà®¾à®°à¯à®¤à¯à®¤à¯ˆà®•à®³à¯

à®…à®±à®¿à®µà¯à®±à¯à®¤à¯à®¤à®²à¯à®•à®³à¯:
1. à®¤à®®à®¿à®´à¯ à®®à¯Šà®´à®¿à®¯à®¿à®²à¯ à®®à®Ÿà¯à®Ÿà¯à®®à¯‡ à®Žà®´à¯à®¤à¯à®™à¯à®•à®³à¯ - à®†à®™à¯à®•à®¿à®²à®®à¯ à®µà¯‡à®£à¯à®Ÿà®¾à®®à¯
2. {word_count['min']}-{word_count['max']} à®µà®¾à®°à¯à®¤à¯à®¤à¯ˆà®•à®³à®¿à®²à¯ à®ªà®¤à®¿à®²à®³à®¿à®¯à¯à®™à¯à®•à®³à¯
3. à®µà®•à¯à®ªà¯à®ªà¯ {grade_level} à®…à®³à®µà¯à®•à¯à®•à¯ à®à®±à¯à®± à®šà¯Šà®±à¯à®•à®³à¯ à®ªà®¯à®©à¯à®ªà®Ÿà¯à®¤à¯à®¤à¯à®™à¯à®•à®³à¯
4. {grade_instruction}

à®®à¯à®•à¯à®•à®¿à®¯à®®à¯: à®®à¯à®´à¯ à®ªà®¤à®¿à®²à¯à®®à¯ à®¤à®®à®¿à®´à®¿à®²à¯ à®®à®Ÿà¯à®Ÿà¯à®®à¯‡ à®¤à®°à¯à®™à¯à®•à®³à¯. à®†à®™à¯à®•à®¿à®² à®µà®¾à®°à¯à®¤à¯à®¤à¯ˆ à®Žà®´à¯à®¤ à®µà¯‡à®£à¯à®Ÿà®¾à®®à¯.

à®‡à®ªà¯à®ªà¯‹à®¤à¯ '{prompt}' à®ªà®±à¯à®±à®¿ à®¤à®®à®¿à®´à®¿à®²à¯ {content_type} à®Žà®´à¯à®¤à¯à®™à¯à®•à®³à¯:
"""
        
        elif language == "gu":
            enhanced_prompt = f"""
àª…àª¤à«àª¯àª‚àª¤ àª®àª¹àª¤à«àªµàªªà«‚àª°à«àª£ àª¸à«‚àªšàª¨àª¾àª“: àª¤àª®àª¾àª°à«‡ àª«àª•à«àª¤ àª—à«àªœàª°àª¾àª¤à«€àª®àª¾àª‚ àªœ àªœàªµàª¾àª¬ àª†àªªàªµàª¾àª¨à«‹ àª›à«‡. àªàª• àªªàª£ àª…àª‚àª—à«àª°à«‡àªœà«€ àª¶àª¬à«àª¦ àªµàª¾àªªàª°àª¶à«‹ àª¨àª¹à«€àª‚.

ABSOLUTELY NO ENGLISH WORDS ALLOWED. GUJARATI ONLY. àª—à«àªœàª°àª¾àª¤à«€àª®àª¾àª‚ àª²àª–à«‹.

àªµàª¿àª·àª¯: {subject}
àª§à«‹àª°àª£: {grade_level}
àªªà«àª°àª¶à«àª¨/àªµàª¿àª·àª¯: {prompt}
àªªà«àª°àª•àª¾àª°: {content_type}
àª¶àª¬à«àª¦ àª®àª°à«àª¯àª¾àª¦àª¾: {word_count['min']}-{word_count['max']} àª¶àª¬à«àª¦à«‹

àª¸à«‚àªšàª¨àª¾àª“:
1. àª«àª•à«àª¤ àª—à«àªœàª°àª¾àª¤à«€ àª­àª¾àª·àª¾àª®àª¾àª‚ àª²àª–à«‹ - àª…àª‚àª—à«àª°à«‡àªœà«€ àª¨àª¹à«€àª‚
2. {word_count['min']}-{word_count['max']} àª¶àª¬à«àª¦à«‹àª®àª¾àª‚ àªœàªµàª¾àª¬ àª†àªªà«‹
3. àª§à«‹àª°àª£ {grade_level} àª…àª¨à«àª¸àª¾àª° àª¶àª¬à«àª¦àª­àª‚àª¡à«‹àª³ àªµàª¾àªªàª°à«‹
4. {grade_instruction}

àª®àª¹àª¤à«àªµàªªà«‚àª°à«àª£: àª¸àª‚àªªà«‚àª°à«àª£ àªœàªµàª¾àª¬ àª«àª•à«àª¤ àª—à«àªœàª°àª¾àª¤à«€àª®àª¾àª‚ àª†àªªà«‹. àª…àª‚àª—à«àª°à«‡àªœà«€àª¨à«‹ àªàª• àªªàª£ àª¶àª¬à«àª¦ àª²àª–àª¶à«‹ àª¨àª¹à«€àª‚.

àª¹àªµà«‡ '{prompt}' àªµàª¿àª¶à«‡ àª—à«àªœàª°àª¾àª¤à«€àª®àª¾àª‚ {content_type} àª²àª–à«‹:
"""
        
        else:
            # For English and any other language, use very strict instructions
            enhanced_prompt = f"""
ðŸš¨ ULTRA CRITICAL LANGUAGE ENFORCEMENT ðŸš¨
LANGUAGE: {language.upper()} ONLY
ABSOLUTELY NO ENGLISH OR OTHER LANGUAGES ALLOWED!

You MUST respond ONLY in {language.upper()} language. Do NOT use English or any other language.

Subject: {subject}
Grade: {grade_level}
Topic: {prompt}
Type: {content_type}
Word limit: {word_count['min']}-{word_count['max']} words EXACTLY

STRICT REQUIREMENTS:
1. Language: {language.upper()} ONLY (zero English words allowed)
2. Word count: {word_count['min']}-{word_count['max']} words (count each word carefully)
3. Grade {grade_level} appropriate vocabulary and concepts
4. {grade_instruction}

ðŸš¨ CRITICAL: Your entire response must be in {language.upper()} language. Count words carefully and stay within {word_count['min']}-{word_count['max']} words limit.

Now write {content_type} about '{prompt}' in {language.upper()} language:
"""
        
        return enhanced_prompt.strip()
    
    def _generate_educational_fallback(self, prompt: str, **kwargs) -> str:
        """Generate educational content when Ollama is not available"""
        language = kwargs.get("language", "en")
        grade_level = kwargs.get("grade_level", "3")
        
        fallback_messages = {
            "hi": f"""
{prompt} à¤•à¥‡ à¤¬à¤¾à¤°à¥‡ à¤®à¥‡à¤‚:

à¤¯à¤¹ à¤à¤• à¤¬à¤¹à¥à¤¤ à¤…à¤šà¥à¤›à¤¾ à¤¸à¤µà¤¾à¤² à¤¹à¥ˆ! à¤œà¤¬ Ollama AI à¤‰à¤ªà¤²à¤¬à¥à¤§ à¤¨à¤¹à¥€à¤‚ à¤¹à¥ˆ, à¤¤à¥‹ à¤¹à¤® à¤†à¤ªà¤•à¥‹ à¤¸à¥à¤à¤¾à¤µ à¤¦à¥‡à¤¤à¥‡ à¤¹à¥ˆà¤‚:

â€¢ à¤ªà¥à¤¸à¥à¤¤à¤•à¥‹à¤‚ à¤¸à¥‡ à¤ªà¤¢à¤¼à¥‡à¤‚
â€¢ à¤¶à¤¿à¤•à¥à¤·à¤•à¥‹à¤‚ à¤¸à¥‡ à¤ªà¥‚à¤›à¥‡à¤‚  
â€¢ à¤‡à¤‚à¤Ÿà¤°à¤¨à¥‡à¤Ÿ à¤ªà¤° à¤–à¥‹à¤œà¥‡à¤‚

à¤•à¥ƒà¤ªà¤¯à¤¾ Ollama à¤¸à¥à¤¥à¤¾à¤ªà¤¿à¤¤ à¤•à¤°à¥‡à¤‚ à¤”à¤° à¤à¤• à¤®à¥‰à¤¡à¤² à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡ à¤•à¤°à¥‡à¤‚ à¤¤à¤¾à¤•à¤¿ à¤†à¤ªà¤•à¥‹ à¤¬à¥‡à¤¹à¤¤à¤° à¤‰à¤¤à¥à¤¤à¤° à¤®à¤¿à¤² à¤¸à¤•à¥‡à¤‚à¥¤

à¤¸à¥€à¤–à¤¤à¥‡ à¤°à¤¹à¥‡à¤‚!
""",
            "mr": f"""
{prompt} à¤¬à¤¦à¥à¤¦à¤²:

à¤¹à¤¾ à¤à¤• à¤›à¤¾à¤¨ à¤ªà¥à¤°à¤¶à¥à¤¨ à¤†à¤¹à¥‡! à¤œà¥‡à¤µà¥à¤¹à¤¾ Ollama AI à¤‰à¤ªà¤²à¤¬à¥à¤§ à¤¨à¤¾à¤¹à¥€, à¤¤à¥‡à¤µà¥à¤¹à¤¾ à¤†à¤®à¥à¤¹à¥€ à¤¸à¥à¤šà¤µà¤¤à¥‹:

â€¢ à¤ªà¥à¤¸à¥à¤¤à¤•à¤¾à¤‚à¤®à¤§à¥‚à¤¨ à¤µà¤¾à¤šà¤¾
â€¢ à¤¶à¤¿à¤•à¥à¤·à¤•à¤¾à¤‚à¤¨à¤¾ à¤µà¤¿à¤šà¤¾à¤°à¤¾
â€¢ à¤‡à¤‚à¤Ÿà¤°à¤¨à¥‡à¤Ÿà¤µà¤° à¤¶à¥‹à¤§à¤¾

à¤•à¥ƒà¤ªà¤¯à¤¾ Ollama à¤¸à¥à¤¥à¤¾à¤ªà¤¿à¤¤ à¤•à¤°à¤¾ à¤†à¤£à¤¿ à¤®à¥‰à¤¡à¥‡à¤² à¤¡à¤¾à¤‰à¤¨à¤²à¥‹à¤¡ à¤•à¤°à¤¾ à¤œà¥‡à¤£à¥‡à¤•à¤°à¥‚à¤¨ à¤¤à¥à¤®à¥à¤¹à¤¾à¤²à¤¾ à¤šà¤¾à¤‚à¤—à¤²à¥€ à¤‰à¤¤à¥à¤¤à¤°à¥‡ à¤®à¤¿à¤³à¤¤à¥€à¤²à¥¤

à¤¶à¤¿à¤•à¤¤ à¤°à¤¾à¤¹à¤¾!
""",
            "bn": f"""
{prompt} à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡:

à¦à¦Ÿà¦¿ à¦à¦•à¦Ÿà¦¿ à¦¦à§à¦°à§à¦¦à¦¾à¦¨à§à¦¤ à¦ªà§à¦°à¦¶à§à¦¨! à¦¯à¦–à¦¨ Ollama AI à¦‰à¦ªà¦²à¦¬à§à¦§ à¦¨à§‡à¦‡, à¦¤à¦–à¦¨ à¦†à¦®à¦°à¦¾ à¦¸à§à¦ªà¦¾à¦°à¦¿à¦¶ à¦•à¦°à¦¿:

â€¢ à¦¬à¦‡ à¦¥à§‡à¦•à§‡ à¦ªà¦¡à¦¼à§à¦¨
â€¢ à¦¶à¦¿à¦•à§à¦·à¦•à¦¦à§‡à¦° à¦œà¦¿à¦œà§à¦žà¦¾à¦¸à¦¾ à¦•à¦°à§à¦¨
â€¢ à¦‡à¦¨à§à¦Ÿà¦¾à¦°à¦¨à§‡à¦Ÿà§‡ à¦…à¦¨à§à¦¸à¦¨à§à¦§à¦¾à¦¨ à¦•à¦°à§à¦¨

à¦¦à¦¯à¦¼à¦¾ à¦•à¦°à§‡ Ollama à¦‡à¦¨à¦¸à§à¦Ÿà¦² à¦•à¦°à§à¦¨ à¦à¦¬à¦‚ à¦à¦•à¦Ÿà¦¿ à¦®à¦¡à§‡à¦² à¦¡à¦¾à¦‰à¦¨à¦²à§‹à¦¡ à¦•à¦°à§à¦¨ à¦¯à¦¾à¦¤à§‡ à¦†à¦ªà¦¨à¦¿ à¦†à¦°à¦“ à¦­à¦¾à¦² à¦‰à¦¤à§à¦¤à¦° à¦ªà§‡à¦¤à§‡ à¦ªà¦¾à¦°à§‡à¦¨à¥¤

à¦¶à§‡à¦–à¦¾ à¦šà¦¾à¦²à¦¿à¦¯à¦¼à§‡ à¦¯à¦¾à¦¨!
""",
            "te": f"""
{prompt} à°—à±à°°à°¿à°‚à°šà°¿:

à°‡à°¦à°¿ à°šà°¾à°²à°¾ à°®à°‚à°šà°¿ à°ªà±à°°à°¶à±à°¨! Ollama AI à°…à°‚à°¦à±à°¬à°¾à°Ÿà±à°²à±‹ à°²à±‡à°¨à°ªà±à°ªà±à°¡à±, à°®à±‡à°®à± à°¸à±‚à°šà°¿à°¸à±à°¤à±à°¨à±à°¨à°¾à°®à±:

â€¢ à°ªà±à°¸à±à°¤à°•à°¾à°² à°¨à±à°‚à°¡à°¿ à°šà°¦à°µà°‚à°¡à°¿
â€¢ à°‰à°ªà°¾à°§à±à°¯à°¾à°¯à±à°²à°¨à± à°…à°¡à°—à°‚à°¡à°¿
â€¢ à°‡à°‚à°Ÿà°°à±à°¨à±†à°Ÿà±à°²à±‹ à°µà±†à°¤à°•à°‚à°¡à°¿

à°¦à°¯à°šà±‡à°¸à°¿ Ollama à°‡à°¨à±à°¸à±à°Ÿà°¾à°²à± à°šà±‡à°¸à°¿, à°®à°¾à°¡à°²à± à°¡à±Œà°¨à±à°²à±‹à°¡à± à°šà±‡à°¯à°‚à°¡à°¿, à°¤à°¦à±à°µà°¾à°°à°¾ à°®à±€à°•à± à°®à±†à°°à±à°—à±ˆà°¨ à°¸à°®à°¾à°§à°¾à°¨à°¾à°²à± à°²à°­à°¿à°¸à±à°¤à°¾à°¯à°¿à¥¤

à°¨à±‡à°°à±à°šà±à°•à±‹à°µà°¡à°‚ à°•à±Šà°¨à°¸à°¾à°—à°¿à°‚à°šà°‚à°¡à°¿!
""",
            "ta": f"""
{prompt} à®ªà®±à¯à®±à®¿:

à®‡à®¤à¯ à®’à®°à¯ à®šà®¿à®±à®¨à¯à®¤ à®•à¯‡à®³à¯à®µà®¿! Ollama AI à®•à®¿à®Ÿà¯ˆà®•à¯à®•à®¾à®¤à®ªà¯‹à®¤à¯, à®¨à®¾à®™à¯à®•à®³à¯ à®ªà®°à®¿à®¨à¯à®¤à¯à®°à¯ˆà®•à¯à®•à®¿à®±à¯‹à®®à¯:

â€¢ à®ªà¯à®¤à¯à®¤à®•à®™à¯à®•à®³à®¿à®²à¯ à®‡à®°à¯à®¨à¯à®¤à¯ à®ªà®Ÿà®¿à®¯à¯à®™à¯à®•à®³à¯
â€¢ à®†à®šà®¿à®°à®¿à®¯à®°à¯à®•à®³à®¿à®Ÿà®®à¯ à®•à¯‡à®³à¯à®™à¯à®•à®³à¯
â€¢ à®‡à®£à¯ˆà®¯à®¤à¯à®¤à®¿à®²à¯ à®¤à¯‡à®Ÿà¯à®™à¯à®•à®³à¯

à®¤à®¯à®µà¯à®šà¯†à®¯à¯à®¤à¯ Ollama à®¨à®¿à®±à¯à®µà®¿ à®®à®¾à®Ÿà®²à¯ˆ à®ªà®¤à®¿à®µà®¿à®±à®•à¯à®•à®®à¯ à®šà¯†à®¯à¯à®¯à¯à®™à¯à®•à®³à¯, à®‡à®¤à®©à®¾à®²à¯ à®šà®¿à®±à®¨à¯à®¤ à®ªà®¤à®¿à®²à¯à®•à®³à¯ à®•à®¿à®Ÿà¯ˆà®•à¯à®•à¯à®®à¯à¥¤

à®•à®±à¯à®±à¯à®•à¯à®•à¯Šà®£à¯à®Ÿà¯‡ à®‡à®°à¯à®™à¯à®•à®³à¯!
""",
            "gu": f"""
{prompt} àªµàª¿àª¶à«‡:

àª† àªàª• àª–à«‚àª¬ àª¸àª¾àª°à«‹ àªªà«àª°àª¶à«àª¨ àª›à«‡! àªœà«àª¯àª¾àª°à«‡ Ollama AI àª‰àªªàª²àª¬à«àª§ àª¨ àª¹à«‹àª¯, àª…àª®à«‡ àª¸à«‚àªšàªµà«€àª àª›à«€àª:

â€¢ àªªà±àª¸à«àª¤àª•à«‹àª®àª¾àª‚àª¥à«€ àªµàª¾àª‚àªšà«‹
â€¢ àª¶àª¿àª•à«àª·àª•à«‹àª¨à«‡ àªªà«‚àª›à«‹
â€¢ àª‡àª¨à«àªŸàª°àª¨à«‡àªŸ àªªàª° àª¶à«‹àª§à«‹

àª•à«ƒàªªàª¾ àª•àª°à«€àª¨à«‡ Ollama àª‡àª¨à«àª¸à«àªŸà«‹àª² àª•àª°à«‹ àª…àª¨à«‡ àª®à«‹àª¡àµ½ àª¡àµ—àµºàª²àµ‹àª¡ àª•àª°à«‹ àªœà«‡àª¥à«€ àª¤àª®àª¨à«‡ àªµàª§à« àª¸àª¾àª°àª¾ àªœàªµàª¾àª¬à«‹ àª®àª³à«‡à¥¤

àª¶à«€àª–àª¤àª¾ àª°àª¹à«‹!
""",
            "kn": f"""
{prompt} à²¬à²—à³à²—à³†:

à²‡à²¦à³ à²’à²‚à²¦à³ à²‰à²¤à³à²¤à²® à²ªà³à²°à²¶à³à²¨à³†! Ollama AI à²²à²­à³à²¯à²µà²¿à²²à³à²²à²¦à²¿à²¦à³à²¦à²¾à²—, à²¨à²¾à²µà³ à²¸à³‚à²šà²¿à²¸à³à²¤à³à²¤à³‡à²µà³†:

â€¢ à²ªà³à²¸à³à²¤à²•à²—à²³à²¿à²‚à²¦ à²“à²¦à²¿
â€¢ à²¶à²¿à²•à³à²·à²•à²°à²¨à³à²¨à³ à²•à³‡à²³à²¿
â€¢ à²‡à²‚à²Ÿà²°à³à²¨àµ†à²Ÿà³â€Œà²¨à²²à³à²²à²¿ à²¹à³à²¡à³à²•à²¿

à²¦à²¯à²µà²¿à²Ÿà³à²Ÿà³ Ollama à²¸à³à²¥à²¾à²ªà²¿à²¸à²¿ à²®à²¤à³à²¤à³ à²®à²¾à²¡à³†à²²à³ à²¡à³Œà²¨à³â€Œà²²à³‹à²¡à³ à²®à²¾à²¡à²¿ à²‡à²¦à²°à²¿à²‚à²¦ à²¨à²¿à²®à²—à³† à²‰à²¤à³à²¤à²® à²‰à²¤à³à²¤à²°à²—à²³à³ à²¸à²¿à²—à³à²¤à³à²¤à²µà³†à¥¤

à²•à²²à²¿à²¯à³à²¤à³à²¤à²¾ à²‡à²°à²¿!
""",
            "ml": f"""
{prompt} à´•àµà´±à´¿à´šàµà´šàµ:

à´‡à´¤àµ à´’à´°àµ à´¨à´²àµà´² à´šàµ‹à´¦àµà´¯à´®à´¾à´£àµ! Ollama AI à´²à´­àµà´¯à´®à´²àµà´²à´¾à´¤àµà´¤à´ªàµà´ªàµ‹àµ¾, à´žà´™àµà´™àµ¾ à´¨à´¿àµ¼à´¦àµà´¦àµ‡à´¶à´¿à´•àµà´•àµà´¨àµà´¨àµ:

â€¢ à´ªàµà´¸àµà´¤à´•à´™àµà´™à´³à´¿àµ½ à´¨à´¿à´¨àµà´¨àµ à´µà´¾à´¯à´¿à´•àµà´•àµà´•
â€¢ à´…à´§àµà´¯à´¾à´ªà´•à´°àµ‹à´Ÿàµ à´šàµ‹à´¦à´¿à´•àµà´•àµà´•
â€¢ à´‡à´¨àµà´±àµ¼à´¨àµ†à´±àµà´±à´¿àµ½ à´¤à´¿à´°à´¯àµà´•

à´¦à´¯à´µà´¾à´¯à´¿ Ollama à´‡àµ»à´¸àµà´±àµà´±à´¾àµ¾ à´šàµ†à´¯àµà´¤àµ à´®àµ‹à´¡àµ½ à´¡àµ—àµºà´²àµ‹à´¡àµ à´šàµ†à´¯àµà´¯àµà´•, à´…à´™àµà´™à´¨àµ† à´¨à´¿à´™àµà´™àµ¾à´•àµà´•àµ à´®à´¿à´•à´šàµà´š à´‰à´¤àµà´¤à´°à´™àµà´™àµ¾ à´²à´­à´¿à´•àµà´•àµà´‚à¥¤

à´ªà´ à´¿à´•àµà´•àµà´¨àµà´¨à´¤àµ à´¤àµà´Ÿà´°àµà´•!
""",
            "ur": f"""
{prompt} Ú©Û’ Ø¨Ø§Ø±Û’ Ù…ÛŒÚº:

ÛŒÛ Ø§ÛŒÚ© Ø¨ÛØªØ±ÛŒÙ† Ø³ÙˆØ§Ù„ ÛÛ’! Ø¬Ø¨ Ollama AI Ø¯Ø³ØªÛŒØ§Ø¨ Ù†ÛÛŒÚº ÛÛ’ ØªÙˆ ÛÙ… ØªØ¬ÙˆÛŒØ² Ú©Ø±ØªÛ’ ÛÛŒÚº:

â€¢ Ú©ØªØ§Ø¨ÙˆÚº Ø³Û’ Ù¾Ú‘Ú¾ÛŒÚº
â€¢ Ø§Ø³Ø§ØªØ°Û Ø³Û’ Ù¾ÙˆÚ†Ú¾ÛŒÚº
â€¢ Ø§Ù†Ù¹Ø±Ù†ÛŒÙ¹ Ù¾Ø± ØªÙ„Ø§Ø´ Ú©Ø±ÛŒÚº

Ø¨Ø±Ø§Ø¦Û’ Ú©Ø±Ù… Ollama Ø§Ù†Ø³Ù¹Ø§Ù„ Ú©Ø±ÛŒÚº Ø§ÙˆØ± Ù…Ø§ÚˆÙ„ ÚˆØ§Ø¤Ù† Ù„ÙˆÚˆ Ú©Ø±ÛŒÚº ØªØ§Ú©Û Ø¢Ù¾ Ú©Ùˆ Ø¨ÛØªØ± Ø¬ÙˆØ§Ø¨Ø§Øª Ù…Ù„ Ø³Ú©ÛŒÚºÛ”

Ø³ÛŒÚ©Ú¾ØªÛ’ Ø±ÛÛŒÚº!
"""
        }
        
        if language in fallback_messages:
            return fallback_messages[language]
        else:
            return f"""
About "{prompt}":

That's a great question! When Ollama AI is not available, we suggest:

â€¢ Read books about this topic
â€¢ Ask your teachers
â€¢ Search on the internet for reliable sources

Please install Ollama and download a model to get better AI-generated answers.

Keep learning!
"""

    # Keep compatibility with existing multimodal methods
    async def generate_multimodal_content(self, prompt: str, image_data: str) -> str:
        return "Multimodal content generation not implemented with Ollama yet."
    
    async def generate_image(self, prompt: str) -> str:
        return "Image generation not implemented with Ollama yet." 